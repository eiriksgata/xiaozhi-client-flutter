import 'dart:async';
import 'dart:io';
import 'dart:typed_data';
import 'package:record/record.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:opus_dart/opus_dart.dart';
import 'package:audio_session/audio_session.dart';
import 'package:mp_audio_stream/mp_audio_stream.dart';
import 'package:xiaozhi_client_flutter/app/config/app_config.dart';

/// éŸ³é¢‘å·¥å…·ç±»ï¼Œç”¨äºå¤„ç†OpuséŸ³é¢‘ç¼–è§£ç å’Œå½•åˆ¶æ’­æ”¾
class AudioUtil {
  static final _mpAudioStream = getAudioStream();

  static const String TAG = "AudioUtil";

  static final AudioRecorder _audioRecorder = AudioRecorder();
  static bool _isRecorderInitialized = false;
  static bool _isPlayerInitialized = false;
  static bool _isRecording = false;
  static bool _isPlaying = false;

  static final StreamController<Uint8List> _audioStreamController =
      StreamController<Uint8List>.broadcast();

  static Timer? _audioProcessingTimer;

  // ğŸ”¥ æŒ¯å¹…ç›¸å…³
  static StreamController<double>? _amplitudeStreamController;
  static StreamSubscription<Amplitude>? _amplitudeSubscription;

  // Opusç›¸å…³
  static final _encoder = SimpleOpusEncoder(
    sampleRate: AppConfig.sampleRate,
    channels: AppConfig.channels,
    application: Application.voip,
  );
  static final _decoder = SimpleOpusDecoder(
    sampleRate: AppConfig.sampleRate,
    channels: AppConfig.channels,
  );

  /// è·å–éŸ³é¢‘æµ
  static Stream<Uint8List> get audioStream => _audioStreamController.stream;

  /// ğŸ”¥ è·å–å½’ä¸€åŒ–æŒ¯å¹…æµ (0.0 ~ 1.0)
  static Stream<double> get amplitudeStream =>
      _amplitudeStreamController?.stream ?? const Stream.empty();

  /// åˆå§‹åŒ–éŸ³é¢‘å½•åˆ¶å™¨
  static Future<void> initRecorder() async {
    if (_isRecorderInitialized) return;

    print('$TAG: å¼€å§‹åˆå§‹åŒ–å½•éŸ³å™¨');

    // æ›´ç§¯æåœ°è¯·æ±‚æ‰€æœ‰å¯èƒ½éœ€è¦çš„æƒé™
    if (Platform.isAndroid) {
      print('$TAG: è¯·æ±‚Androidæ‰€éœ€çš„æ‰€æœ‰æƒé™');
      Map<Permission, PermissionStatus> statuses = await [
        Permission.microphone,
        Permission.storage,
        Permission.manageExternalStorage,
        Permission.bluetooth,
        Permission.bluetoothConnect,
        Permission.bluetoothScan,
      ].request();

      print('$TAG: æƒé™çŠ¶æ€:');
      statuses.forEach((permission, status) {
        print('$TAG: $permission: $status');
      });

      if (statuses[Permission.microphone] != PermissionStatus.granted) {
        print('$TAG: éº¦å…‹é£æƒé™è¢«æ‹’ç»');
        throw Exception('éœ€è¦éº¦å…‹é£æƒé™');
      }
    } else {
      // iOS/å…¶ä»–å¹³å°åªè¯·æ±‚éº¦å…‹é£æƒé™
      final status = await Permission.microphone.request();
      if (status != PermissionStatus.granted) {
        print('$TAG: éº¦å…‹é£æƒé™è¢«æ‹’ç»');
        throw Exception('éœ€è¦éº¦å…‹é£æƒé™');
      }
    }

    // æ£€æŸ¥æ˜¯å¦å¯ç”¨
    print('$TAG: æ£€æŸ¥PCM16ç¼–ç æ˜¯å¦æ”¯æŒ');
    final isAvailable = await _audioRecorder.isEncoderSupported(
      AudioEncoder.pcm16bits,
    );
    print('$TAG: PCM16ç¼–ç æ”¯æŒçŠ¶æ€: $isAvailable');

    // è®¾ç½®éŸ³é¢‘æ¨¡å¼ - å‚è€ƒAndroidåŸç”Ÿå®ç°
    print('$TAG: é…ç½®éŸ³é¢‘ä¼šè¯');
    final session = await AudioSession.instance;

    // ä½¿ç”¨ä¸åŸç”ŸAndroidå®ç°æ›´æ¥è¿‘çš„é…ç½®
    if (Platform.isAndroid) {
      await session.configure(
        const AudioSessionConfiguration(
          avAudioSessionCategory: AVAudioSessionCategory.playAndRecord,
          avAudioSessionCategoryOptions:
              AVAudioSessionCategoryOptions.allowBluetooth,
          avAudioSessionMode: AVAudioSessionMode.voiceChat,
          androidAudioAttributes: AndroidAudioAttributes(
            contentType: AndroidAudioContentType.speech,
            usage: AndroidAudioUsage.voiceCommunication,
            flags: AndroidAudioFlags.audibilityEnforced,
          ),
          androidAudioFocusGainType:
              AndroidAudioFocusGainType.gainTransientExclusive,
          androidWillPauseWhenDucked: false,
        ),
      );
    } else {
      await session.configure(
        const AudioSessionConfiguration(
          avAudioSessionCategory: AVAudioSessionCategory.playAndRecord,
          avAudioSessionCategoryOptions:
              AVAudioSessionCategoryOptions.allowBluetooth,
          avAudioSessionMode: AVAudioSessionMode.voiceChat,
        ),
      );
      await session.setActive(true);
    }

    _isRecorderInitialized = true;
    print('$TAG: å½•éŸ³å™¨åˆå§‹åŒ–æˆåŠŸ');
  }

  /// åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å™¨
  static Future<void> initPlayer() async {
    // ç¡®ä¿ä»»ä½•æ—§æ’­æ”¾å™¨è¢«é‡Šæ”¾
    await stopPlaying();

    try {
      print('$TAG: åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å™¨ - å•å£°é“ 16kHz');

      // åˆå§‹åŒ–ä¸ºå•å£°é“ï¼ŒåŒ¹é… Opus è§£ç å™¨è¾“å‡º
      _mpAudioStream.init(
        channels: AppConfig.channels, // ä½¿ç”¨å•å£°é“ï¼ŒåŒ¹é… Opus
        sampleRate: AppConfig.sampleRate, // 16000 Hz
      );
      _mpAudioStream.resume(); // å¼€å§‹æ’­æ”¾

      _isPlayerInitialized = true;
      print(
        '$TAG: éŸ³é¢‘æ’­æ”¾å™¨åˆå§‹åŒ–æˆåŠŸ - ${AppConfig.channels}å£°é“ ${AppConfig.sampleRate}Hz',
      );
    } catch (e) {
      print('$TAG: éŸ³é¢‘æ’­æ”¾å™¨åˆå§‹åŒ–å¤±è´¥: $e');
      _isPlayerInitialized = false;
    }
  }

  /// æ’­æ”¾OpuséŸ³é¢‘æ•°æ®
  static Future<void> playOpusData(Uint8List opusData) async {
    try {
      // å¦‚æœæ’­æ”¾å™¨æœªåˆå§‹åŒ–ï¼Œå…ˆåˆå§‹åŒ–
      if (!_isPlayerInitialized) {
        await initPlayer();
      }

      //print('$TAG: æ¥æ”¶åˆ° Opus æ•°æ®: ${opusData.length} å­—èŠ‚');

      // è§£ç Opusæ•°æ®
      final Int16List pcmData = _decoder.decode(input: opusData);
      //print('$TAG: è§£ç å PCM æ•°æ®: ${pcmData.length} æ ·æœ¬');

      // è½¬æ¢ Int16 PCM æ•°æ®åˆ° Float32 æ ¼å¼ (mp_audio_stream éœ€è¦)
      final Float32List float32Data = Float32List(pcmData.length);
      for (int i = 0; i < pcmData.length; i++) {
        // å½’ä¸€åŒ–åˆ° -1.0 åˆ° 1.0 èŒƒå›´
        float32Data[i] = pcmData[i] / 32768.0;
      }

      //print('$TAG: è½¬æ¢ä¸º Float32 æ•°æ®: ${float32Data.length} æ ·æœ¬');
      //print('$TAG: å‰å‡ ä¸ªæ ·æœ¬å€¼: ${float32Data.take(5).toList()}');

      // å‘é€åˆ° mp_audio_stream
      _mpAudioStream.push(float32Data);
      //print('$TAG: éŸ³é¢‘æ•°æ®å·²æ¨é€åˆ°æ’­æ”¾å™¨');
    } catch (e, stackTrace) {
      print('$TAG: æ’­æ”¾å¤±è´¥: $e');
      print('$TAG: å †æ ˆ: $stackTrace');

      // ç®€å•é‡ç½®å¹¶é‡æ–°åˆå§‹åŒ–
      await stopPlaying();
      await initPlayer();
    }
  }

  /// åœæ­¢æ’­æ”¾
  static Future<void> stopPlaying() async {
    if (_isPlayerInitialized) {
      try {
        // mp_audio_stream æ²¡æœ‰ stop æ–¹æ³•ï¼Œä½¿ç”¨ dispose æ¥å®Œå…¨é‡Šæ”¾
        // æˆ–è€…ç®€å•åœ°æ ‡è®°ä¸ºæœªåˆå§‹åŒ–ï¼Œéœ€è¦æ—¶é‡æ–°åˆå§‹åŒ–
        print('$TAG: æ’­æ”¾å™¨å·²åœæ­¢');
      } catch (e) {
        print('$TAG: åœæ­¢æ’­æ”¾å¤±è´¥: $e');
      }
      _isPlayerInitialized = false;
    }
  }

  /// é‡Šæ”¾èµ„æº
  static Future<void> dispose() async {
    _audioStreamController.close();
    print('$TAG: èµ„æºå·²é‡Šæ”¾');
  }

  /// å¼€å§‹å½•éŸ³
  /// [enableAEC] - æ˜¯å¦å¯ç”¨å›å£°æ¶ˆé™¤ï¼ˆAECï¼‰å’Œé™å™ªï¼ŒæŒç»­ç›‘å¬æ¨¡å¼å»ºè®®å¼€å¯
  static Future<void> startRecording({bool enableAEC = false}) async {
    if (!_isRecorderInitialized) {
      await initRecorder();
    }

    if (_isRecording) return;

    try {
      print('$TAG: å°è¯•å¯åŠ¨å½•éŸ³ (AEC: $enableAEC)');

      // ç¡®ä¿éº¦å…‹é£æƒé™å·²è·å– - ä½¿ç”¨ä¸åŒæ–¹å¼æ£€æŸ¥æƒé™
      final status = await Permission.microphone.status;
      print('$TAG: éº¦å…‹é£æƒé™çŠ¶æ€: $status');

      if (status != PermissionStatus.granted) {
        final result = await Permission.microphone.request();
        print('$TAG: è¯·æ±‚éº¦å…‹é£æƒé™ç»“æœ: $result');
        if (result != PermissionStatus.granted) {
          print('$TAG: éº¦å…‹é£æƒé™è¢«æ‹’ç»');
          return;
        }
      }

      // å°è¯•ç›´æ¥ä½¿ç”¨éŸ³é¢‘æµ
      try {
        print('$TAG: å°è¯•å¯åŠ¨æµå¼å½•éŸ³ (AEC: $enableAEC, é™å™ª: $enableAEC, AGC: $enableAEC)');
        final stream = await _audioRecorder.startStream(
          RecordConfig(
            encoder: AudioEncoder.pcm16bits,
            sampleRate: AppConfig.sampleRate,
            numChannels: AppConfig.channels,
            // ğŸ”¥ AEC å›å£°æ¶ˆé™¤ - æŒç»­ç›‘å¬æ¨¡å¼ä¸‹éœ€è¦æ¶ˆé™¤æ‰¬å£°å™¨æ’­æ”¾çš„å›å£°
            echoCancel: enableAEC,
            // ğŸ”¥ é™å™ª - å‡å°‘èƒŒæ™¯å™ªéŸ³
            noiseSuppress: enableAEC,
            // ğŸ”¥ è‡ªåŠ¨å¢ç›Šæ§åˆ¶ - è‡ªåŠ¨è°ƒæ•´éº¦å…‹é£éŸ³é‡
            autoGain: enableAEC,
          ),
        );

        _isRecording = true;
        print('$TAG: æµå¼å½•éŸ³å¯åŠ¨æˆåŠŸ');

        // ğŸ”¥ å¯åŠ¨æŒ¯å¹…ç›‘å¬
        _amplitudeStreamController = StreamController<double>.broadcast();
        _amplitudeSubscription = _audioRecorder
            .onAmplitudeChanged(const Duration(milliseconds: 100))
            .listen((amp) {
          // å°† dBFS (-60 ~ 0) è½¬æ¢ä¸º 0.0 ~ 1.0
          // dBFS æ˜¯è´Ÿå€¼ï¼Œ0 è¡¨ç¤ºæœ€å¤§éŸ³é‡ï¼Œ-60 è¡¨ç¤ºé™éŸ³
          final normalized = ((amp.current + 50) / 50).clamp(0.0, 1.0);
          _amplitudeStreamController?.add(normalized);
        });

        // ç›´æ¥ä»æµä¸­å¤„ç†æ•°æ®
        stream.listen(
          (data) async {
            if (data.isNotEmpty && data.length % 2 == 0) {
              final opusData = await encodeToOpus(data);
              if (opusData != null) {
                _audioStreamController.add(opusData);
              }
            }
          },
          onError: (error) {
            print('$TAG: éŸ³é¢‘æµé”™è¯¯: $error');
            _isRecording = false;
          },
          onDone: () {
            print('$TAG: éŸ³é¢‘æµç»“æŸ');
            _isRecording = false;
          },
        );
      } catch (e) {
        print('$TAG: æµå¼å½•éŸ³å¤±è´¥: $e');
        _isRecording = false;
        rethrow;
      }
    } catch (e, stackTrace) {
      print('$TAG: å¯åŠ¨å½•éŸ³å¤±è´¥: $e');
      print(stackTrace);
      _isRecording = false;
    }
  }

  /// åœæ­¢å½•éŸ³
  static Future<String?> stopRecording() async {
    if (!_isRecorderInitialized || !_isRecording) return null;

    // å–æ¶ˆå®šæ—¶å™¨
    _audioProcessingTimer?.cancel();

    // ğŸ”¥ å–æ¶ˆæŒ¯å¹…è®¢é˜…
    await _amplitudeSubscription?.cancel();
    _amplitudeSubscription = null;
    await _amplitudeStreamController?.close();
    _amplitudeStreamController = null;

    // åœæ­¢å½•éŸ³
    try {
      final path = await _audioRecorder.stop();
      _isRecording = false;
      print('$TAG: åœæ­¢å½•éŸ³: $path');
      return path;
    } catch (e) {
      print('$TAG: åœæ­¢å½•éŸ³å¤±è´¥: $e');
      _isRecording = false;
      return null;
    }
  }

  /// å°†PCMæ•°æ®ç¼–ç ä¸ºOpusæ ¼å¼
  static Future<Uint8List?> encodeToOpus(Uint8List pcmData) async {
    try {
      // åˆ é™¤é¢‘ç¹æ—¥å¿—
      // è½¬æ¢PCMæ•°æ®ä¸ºInt16List (å°ç«¯å­—èŠ‚åºï¼Œä¸Androidä¸€è‡´)
      final Int16List pcmInt16 = Int16List.fromList(
        List.generate(
          pcmData.length ~/ 2,
          (i) => (pcmData[i * 2]) | (pcmData[i * 2 + 1] << 8),
        ),
      );

      // ç¡®ä¿æ•°æ®é•¿åº¦ç¬¦åˆOpusè¦æ±‚ï¼ˆå¿…é¡»æ˜¯2.5msã€5msã€10msã€20msã€40msæˆ–60msçš„é‡‡æ ·æ•°ï¼‰
      final int samplesPerFrame =
          (AppConfig.sampleRate * AppConfig.frameDuration) ~/ 1000;

      Uint8List encoded;

      // å¤„ç†è¿‡çŸ­çš„æ•°æ®
      if (pcmInt16.length < samplesPerFrame) {
        // å¯¹äºè¿‡çŸ­çš„æ•°æ®ï¼Œå¯ä»¥é€šè¿‡æ·»åŠ é™éŸ³æ¥å¡«å……åˆ°æ‰€éœ€é•¿åº¦
        final Int16List paddedData = Int16List(samplesPerFrame);
        for (int i = 0; i < pcmInt16.length; i++) {
          paddedData[i] = pcmInt16[i];
        }

        // ç¼–ç å¡«å……åçš„æ•°æ®
        encoded = Uint8List.fromList(_encoder.encode(input: paddedData));
      } else {
        // å¯¹äºè¶³å¤Ÿé•¿çš„æ•°æ®ï¼Œè£å‰ªåˆ°ç²¾ç¡®çš„å¸§é•¿åº¦
        encoded = Uint8List.fromList(
          _encoder.encode(input: pcmInt16.sublist(0, samplesPerFrame)),
        );
      }

      return encoded;
    } catch (e, stackTrace) {
      print('$TAG: Opusç¼–ç å¤±è´¥: $e');
      print(stackTrace);
      return null;
    }
  }

  /// æ£€æŸ¥æ˜¯å¦æ­£åœ¨å½•éŸ³
  static bool get isRecording => _isRecording;

  /// æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾
  static bool get isPlaying => _isPlaying;
}
